# ğŸš€ INKSight - AI-Powered RAG Assistant

<div align="center">

**Intelligent document processing system based on Retrieval-Augmented Generation**

[![Python](https://img.shields.io/badge/Python-3.12+-blue.svg)](https://www.python.org/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.116+-green.svg)](https://fastapi.tiangolo.com/)
[![React](https://img.shields.io/badge/React-18+-61dafb.svg)](https://reactjs.org/)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.8+-3178c6.svg)](https://www.typescriptlang.org/)

</div>

---

## ğŸ“‹ About

**INKSight** is a modern document processing system that combines vector search capabilities with large language models. The system allows you to upload documents, index their content, and get accurate answers to questions with source citations.

### âœ¨ Key Features

- ğŸ” **Vector Search** â€” fast semantic search across documents
- ğŸ’¬ **Intelligent Chat** â€” interact with an AI assistant based on your documents
- ğŸ“„ **Document Processing** â€” support for PDF and text files
- ğŸ”„ **Reranking** â€” improved relevance of search results
- ğŸ” **Authentication** â€” secure access to the system
- ğŸ³ **Docker Deployment** â€” easy deployment via Docker Compose
- ğŸ“Š **Monitoring** â€” integration with LangSmith for request tracking

---

## ğŸ—ï¸ Architecture

```
rag_chat/
â”œâ”€â”€ backend/              # Python FastAPI backend
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â””â”€â”€ agentic_rag/
â”‚   â”‚       â”œâ”€â”€ api/      # API endpoints and routes
â”‚   â”‚       â”œâ”€â”€ core/     # Configuration and utilities
â”‚   â”‚       â”œâ”€â”€ models/   # LLM models
â”‚   â”‚       â””â”€â”€ services/ # Business logic
â”‚   â”œâ”€â”€ main.py          # FastAPI entry point
â”‚   â”œâ”€â”€ cli.py           # CLI tools
â”‚   â””â”€â”€ vector_store/    # Vector database
â”‚
â”œâ”€â”€ frontend/            # React TypeScript frontend
â”‚   â”œâ”€â”€ src/            # React components
â”‚   â””â”€â”€ dist/           # Built static assets
â”‚
â”œâ”€â”€ data/               # Source documents for indexing
â”œâ”€â”€ docker-compose.yml  # Docker configuration
â””â”€â”€ deploy.sh          # Deployment script
```

### System Components

- **Backend (FastAPI)** â€” REST API for request processing, vector store operations, and LLM integration
- **Frontend (React)** â€” modern web interface for system interaction
- **Vector Store (ChromaDB)** â€” vector database for storing document embeddings
- **LLM Integration** â€” integration with OpenRouter and local models
- **Document Processor** â€” document processing and chunking

---

## ğŸ› ï¸ Tech Stack

### Backend
- **FastAPI** â€” modern Python web framework
- **LangChain** â€” framework for working with LLMs
- **ChromaDB** â€” vector database
- **Sentence Transformers** â€” models for creating embeddings
- **UV** â€” fast Python package manager
- **Pydantic** â€” data validation

### Frontend
- **React 18** â€” library for building user interfaces
- **TypeScript** â€” typed JavaScript
- **Vite** â€” fast build tool and dev server
- **Tailwind CSS** â€” utility-first CSS framework
- **TanStack Query** â€” server state management
- **Axios** â€” HTTP client

---

## ğŸ“¦ Installation & Setup

### Requirements

- Python 3.12+
- Node.js 18+ and npm
- Docker and Docker Compose (for deployment)
- OpenRouter API key (or local model configuration)

### Local Development

#### 1. Backend Setup

```bash
cd backend

# Install dependencies with uv
uv sync

# Copy environment template
cp .env.example .env
```

Configure the `.env` file:

```env
# Required parameters
OPENROUTER_API_KEY=your_openrouter_api_key_here
AGENT_LLM_MODEL=your_model_name
AGENT_API_KEY=your_api_key
AGENT_BASE_URL=your_base_url

# Optional parameters
LANGCHAIN_API_KEY=your_langsmith_api_key  # For tracing
LANGCHAIN_PROJECT=inksight                # Project name in LangSmith
SECRET_KEY=your-secret-key                # For JWT tokens
```

#### 2. Prepare Vector Database

```bash
cd backend

# Process documents from data folder
uv run python cli.py process ../data --clear

# Check vector store status
uv run python cli.py info
```

#### 3. Run Backend

```bash
cd backend
uv run python main.py --host 0.0.0.0 --port 8000
```

Backend will be available at: `http://localhost:8000`
API documentation: `http://localhost:8000/docs`

#### 4. Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Build project
npm run build

# Run dev server
npm run dev
```

Frontend will be available at: `http://localhost:3000`

---

## ğŸš€ Docker Deployment

### Quick Start

```bash
# Copy and configure .env
cp .env.example .env
# Edit .env file with your API keys

# Run deployment
chmod +x deploy.sh
./deploy.sh
```

### Manual Deployment

```bash
# Build images
docker-compose build

# Start services
docker-compose up -d

# View logs
docker-compose logs -f
```

### Service Management

```bash
# Check status
docker-compose ps

# Stop services
docker-compose down

# Restart services
docker-compose restart

# View logs for specific service
docker-compose logs -f backend
docker-compose logs -f frontend
```

After deployment:
- **Frontend**: `http://localhost:8020`
- **Backend API**: `http://localhost:8010`
- **API Docs**: `http://localhost:8010/docs`

### Default Credentials

- **Username**: `testuser`
- **Password**: `secret`

> âš ï¸ **Important**: Change the default password in production!

---

## ğŸ“¡ API Endpoints

### Authentication

- `POST /api/v1/auth/login` â€” login to the system
- `GET /api/v1/auth/me` â€” current user information

### Main Endpoints

- `POST /api/v1/chat` â€” chat with AI assistant
- `POST /api/v1/search` â€” search knowledge base
- `POST /api/v1/upload` â€” upload documents
- `POST /api/v1/process-documents` â€” process documents
- `GET /api/v1/store-info` â€” vector store information
- `GET /api/v1/supported-formats` â€” supported file formats
- `POST /api/v1/clear-memory` â€” clear chat history
- `GET /api/v1/health` â€” system health check

Full API documentation available at: `http://localhost:8000/docs`

### API Usage Example

```bash
# Login
curl -X POST http://localhost:8000/api/v1/auth/login \
  -H "Content-Type: application/json" \
  -d '{"username": "testuser", "password": "secret"}'

# Send message (requires auth token)
curl -X POST http://localhost:8000/api/v1/chat \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer YOUR_TOKEN" \
  -d '{"message": "What is machine learning?", "include_sources": true}'
```

---

## ğŸ’» CLI Usage

The backend provides CLI tools for system management:

```bash
cd backend

# Process documents
uv run python cli.py process <path_to_documents> [--clear]

# Vector store information
uv run python cli.py info

# Clear vector store
uv run python cli.py clear
```

### Examples

```bash
# Process documents from data folder
uv run python cli.py process ../data

# Process with clearing existing database
uv run python cli.py process ../data --clear

# Check status
uv run python cli.py info
```

---

## âš™ï¸ Configuration

### Environment Variables

#### Required

- `OPENROUTER_API_KEY` â€” OpenRouter API key
- `AGENT_LLM_MODEL` â€” LLM model name
- `AGENT_API_KEY` â€” API key for model access
- `AGENT_BASE_URL` â€” base URL for model API

#### Optional

- `LANGCHAIN_API_KEY` â€” key for LangSmith (tracing)
- `LANGCHAIN_PROJECT` â€” project name in LangSmith
- `SECRET_KEY` â€” secret key for JWT tokens
- `USE_LOCAL_MODEL` â€” use local model
- `HOST` â€” server host (default: `0.0.0.0`)
- `PORT` â€” server port (default: `8000`)

### Document Processing Parameters

Settings can be changed in `backend/src/agentic_rag/core/config.py`:

- `chunk_size` â€” chunk size (default: 1000)
- `chunk_overlap` â€” overlap between chunks (default: 200)
- `embedding_model` â€” embedding model
- `default_k` â€” number of search results (default: 4)
- `enable_reranker` â€” enable reranking (default: `False`)

### User Management

Users are stored in `backend/users.json`. To add a new user:

```json
{
  "users": [
    {
      "username": "admin",
      "hashed_password": "bcrypt_hashed_password",
      "is_active": true
    }
  ]
}
```

> ğŸ’¡ Use CLI or API for secure user creation with password hashing.

---

## ğŸ“š Supported Formats

- **PDF** â€” PDF documents
- **TXT** â€” text files

Maximum file size: 10MB

---

## ğŸ”§ Development

### Project Structure

```
backend/src/agentic_rag/
â”œâ”€â”€ api/              # API endpoints
â”‚   â”œâ”€â”€ routes.py     # Main routes
â”‚   â”œâ”€â”€ auth_routes.py # Authentication routes
â”‚   â””â”€â”€ models.py     # Pydantic models
â”œâ”€â”€ core/             # System core
â”‚   â”œâ”€â”€ config.py     # Configuration
â”‚   â”œâ”€â”€ auth.py       # Authentication
â”‚   â””â”€â”€ tracing.py    # Tracing
â”œâ”€â”€ models/           # LLM models
â”‚   â””â”€â”€ llm.py        # LLM integration
â””â”€â”€ services/         # Services
    â”œâ”€â”€ agent.py      # AI agent
    â”œâ”€â”€ retrieval.py  # Search
    â”œâ”€â”€ reranker.py   # Reranking
    â”œâ”€â”€ vector_store.py # Vector store
    â”œâ”€â”€ text_splitter.py # Text splitting
    â”œâ”€â”€ file_processor.py # File processing
    â”œâ”€â”€ document_loader.py # Document loading
    â””â”€â”€ prompts.py    # Prompts
```

### Development Mode

```bash
# Backend with auto-reload
cd backend
uv run uvicorn main:app --reload --host 0.0.0.0 --port 8000

# Frontend in dev mode
cd frontend
npm run dev
```

---

## ğŸ› Troubleshooting

### Vector Store Issues

If the system cannot find documents:

```bash
cd backend
uv run python cli.py process ../data --clear
```

### API Key Issues

Make sure all required environment variables are set in the `.env` file:

```bash
# Check environment variables
cd backend
cat .env
```

### Docker Issues

```bash
# Rebuild images
docker-compose build --no-cache

# Clean and restart
docker-compose down -v
docker-compose up -d
```

### Dependency Issues

```bash
# Backend
cd backend
uv sync --upgrade

# Frontend
cd frontend
rm -rf node_modules package-lock.json
npm install
```

---

## ğŸ“ License

MIT License

---

## ğŸ‘¥ Authors

- **Aleksandr Tulenkov** â€” [@AleksandrTulenkov](https://github.com/AleksandrTulenkov)
- **Ivan Ulitin** â€” [@QQQiwi](https://github.com/QQQiwi)
- **Alexey Rastorguev** â€” [@Rastorguev763](https://github.com/Rastorguev763)
- **Maxim Novopoltsev** â€” [@maximazzik](https://github.com/maximazzik)
- **Ruslan Murtazin** â€” [@soltkreig](https://github.com/soltkreig)

---

## ğŸ™ Acknowledgments

- [LangChain](https://www.langchain.com/) â€” for the excellent LLM framework
- [FastAPI](https://fastapi.tiangolo.com/) â€” for the fast and modern web framework
- [ChromaDB](https://www.trychroma.com/) â€” for the vector database
- [OpenRouter](https://openrouter.ai/) â€” for access to various LLM models

---

<div align="center">

**Made with â¤ï¸ for efficient document processing**

</div>
